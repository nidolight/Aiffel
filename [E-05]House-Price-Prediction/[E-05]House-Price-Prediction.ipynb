{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_uuid": "38bfbd5ada16035c96bb21265c51de80361f17b4"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import os\n",
    "from os.path import join\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import missingno as msno\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import KFold, cross_val_score, GridSearchCV\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "7d34243045b8e681bf168dc908a9388a2ceb5fa3"
   },
   "outputs": [],
   "source": [
    "train_data_path = join('./data', 'train.csv')\n",
    "sub_data_path = join('./data', 'test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "7f0d3320a32138c92ed7b0629a57bd5a719603b0"
   },
   "source": [
    "---\n",
    "## 1. 데이터 살펴보기\n",
    "pandas의 read_csv 함수를 사용해 데이터를 읽어오고, 각 변수들이 나타내는 의미를 살펴보겠습니다.\n",
    "1. ID : 집을 구분하는 번호\n",
    "2. date : 집을 구매한 날짜\n",
    "3. price : 타겟 변수인 집의 가격\n",
    "4. bedrooms : 침실의 수\n",
    "5. bathrooms : 침실당 화장실 개수\n",
    "6. sqft_living : 주거 공간의 평방 피트\n",
    "7. sqft_lot : 부지의 평방 피트\n",
    "8. floors : 집의 층 수\n",
    "9. waterfront : 집의 전방에 강이 흐르는지 유무 (a.k.a. 리버뷰)\n",
    "10. view : 집이 얼마나 좋아 보이는지의 정도\n",
    "11. condition : 집의 전반적인 상태\n",
    "12. grade : King County grading 시스템 기준으로 매긴 집의 등급\n",
    "13. sqft_above : 지하실을 제외한 평방 피트\n",
    "14. sqft_basement : 지하실의 평방 피트\n",
    "15. yr_built : 집을 지은 년도\n",
    "16. yr_renovated : 집을 재건축한 년도\n",
    "17. zipcode : 우편번호\n",
    "18. lat : 위도\n",
    "19. long : 경도\n",
    "20. sqft_living15 : 2015년 기준 주거 공간의 평방 피트(집을 재건축했다면, 변화가 있을 수 있음)\n",
    "21. sqft_lot15 : 2015년 기준 부지의 평방 피트(집을 재건축했다면, 변화가 있을 수 있음)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "df5891d33b4d5f08c0011b712f8796417564ec17"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data dim : (15035, 21)\n",
      "sub data dim : (6468, 20)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(train_data_path)\n",
    "sub = pd.read_csv(sub_data_path)\n",
    "print('train data dim : {}'.format(data.shape))\n",
    "print('sub data dim : {}'.format(sub.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "251c25b4f9c89db8b6643448369198e94437cfd7"
   },
   "outputs": [],
   "source": [
    "y = data['price']\n",
    "\n",
    "del data['price'] #학습을 위해 타깃정보 제외"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "dc5d87141207fedeb521461bd0d0cc23c0c594f2"
   },
   "outputs": [],
   "source": [
    "train_len = len(data)\n",
    "data = pd.concat((data, sub), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "96537247c40a4932e581a5c681d73348f6b3936b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>condition</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>20141013T000000</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1180</td>\n",
       "      <td>5650</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1180</td>\n",
       "      <td>0</td>\n",
       "      <td>1955</td>\n",
       "      <td>0</td>\n",
       "      <td>98178</td>\n",
       "      <td>47.5112</td>\n",
       "      <td>-122.257</td>\n",
       "      <td>1340</td>\n",
       "      <td>5650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>20150225T000000</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>770</td>\n",
       "      <td>10000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>770</td>\n",
       "      <td>0</td>\n",
       "      <td>1933</td>\n",
       "      <td>0</td>\n",
       "      <td>98028</td>\n",
       "      <td>47.7379</td>\n",
       "      <td>-122.233</td>\n",
       "      <td>2720</td>\n",
       "      <td>8062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>20150218T000000</td>\n",
       "      <td>3</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1680</td>\n",
       "      <td>8080</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1680</td>\n",
       "      <td>0</td>\n",
       "      <td>1987</td>\n",
       "      <td>0</td>\n",
       "      <td>98074</td>\n",
       "      <td>47.6168</td>\n",
       "      <td>-122.045</td>\n",
       "      <td>1800</td>\n",
       "      <td>7503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>20140627T000000</td>\n",
       "      <td>3</td>\n",
       "      <td>2.25</td>\n",
       "      <td>1715</td>\n",
       "      <td>6819</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1715</td>\n",
       "      <td>0</td>\n",
       "      <td>1995</td>\n",
       "      <td>0</td>\n",
       "      <td>98003</td>\n",
       "      <td>47.3097</td>\n",
       "      <td>-122.327</td>\n",
       "      <td>2238</td>\n",
       "      <td>6819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>20150115T000000</td>\n",
       "      <td>3</td>\n",
       "      <td>1.50</td>\n",
       "      <td>1060</td>\n",
       "      <td>9711</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1060</td>\n",
       "      <td>0</td>\n",
       "      <td>1963</td>\n",
       "      <td>0</td>\n",
       "      <td>98198</td>\n",
       "      <td>47.4095</td>\n",
       "      <td>-122.315</td>\n",
       "      <td>1650</td>\n",
       "      <td>9711</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id             date  bedrooms  bathrooms  sqft_living  sqft_lot  floors  \\\n",
       "0   0  20141013T000000         3       1.00         1180      5650     1.0   \n",
       "1   1  20150225T000000         2       1.00          770     10000     1.0   \n",
       "2   2  20150218T000000         3       2.00         1680      8080     1.0   \n",
       "3   3  20140627T000000         3       2.25         1715      6819     2.0   \n",
       "4   4  20150115T000000         3       1.50         1060      9711     1.0   \n",
       "\n",
       "   waterfront  view  condition  grade  sqft_above  sqft_basement  yr_built  \\\n",
       "0           0     0          3      7        1180              0      1955   \n",
       "1           0     0          3      6         770              0      1933   \n",
       "2           0     0          3      8        1680              0      1987   \n",
       "3           0     0          3      7        1715              0      1995   \n",
       "4           0     0          3      7        1060              0      1963   \n",
       "\n",
       "   yr_renovated  zipcode      lat     long  sqft_living15  sqft_lot15  \n",
       "0             0    98178  47.5112 -122.257           1340        5650  \n",
       "1             0    98028  47.7379 -122.233           2720        8062  \n",
       "2             0    98074  47.6168 -122.045           1800        7503  \n",
       "3             0    98003  47.3097 -122.327           2238        6819  \n",
       "4             0    98198  47.4095 -122.315           1650        9711  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "39cc64c64be8d6f2ebd5c7c2523973bbcfb29c94"
   },
   "source": [
    "---\n",
    "## 2. 데이터 전처리 \n",
    "각 변수들에 대해 결측 유무를 확인하고, 분포를 확인해보면서 전처리를 하겠습니다.\n",
    "### 결측치 확인\n",
    "먼저 데이터에 결측치가 있는지를 확인하겠습니다.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "6f406f14203d742ff26da3454935aa05c8364922"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id : 0\n",
      "date : 0\n",
      "bedrooms : 0\n",
      "bathrooms : 0\n",
      "sqft_living : 0\n",
      "sqft_lot : 0\n",
      "floors : 0\n",
      "waterfront : 0\n",
      "view : 0\n",
      "condition : 0\n",
      "grade : 0\n",
      "sqft_above : 0\n",
      "sqft_basement : 0\n",
      "yr_built : 0\n",
      "yr_renovated : 0\n",
      "zipcode : 0\n",
      "lat : 0\n",
      "long : 0\n",
      "sqft_living15 : 0\n",
      "sqft_lot15 : 0\n"
     ]
    }
   ],
   "source": [
    "for c in data.columns:\n",
    "    print('{} : {}'.format(c, len(data.loc[pd.isnull(data[c]), c].values)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "94ad23d7a91a68c1be7fcd4953013f5353541545"
   },
   "source": [
    "### id, date 변수 정리\n",
    "id 변수는 모델이 집값을 예측하는데 도움을 주지 않으므로 제거합니다.<br>\n",
    "date 변수는 연월일시간으로 값을 가지고 있는데, 연월만 고려하는 범주형 변수로 만들겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "6c48e1c16ec0725128286a0d524faff9bd725ed4"
   },
   "outputs": [],
   "source": [
    "sub_id = data['id'][train_len:]\n",
    "del data['id']\n",
    "data['date'] = data['date'].apply(lambda x : str(x[:6])).astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 변수 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21503, 29)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def feature(x):\n",
    "    x['whether_to_renovated']=(x.yr_renovated!=0).astype(int)\n",
    "    x.loc[x.yr_renovated==0,'yr_renovated']=x[x.yr_renovated==0].yr_built\n",
    "    x.drop(['yr_built'],axis=1)\n",
    "    x['garret']=(x.floors%1==0.5).astype(int)\n",
    "    x.loc[x.floors%1==0.5,'floors']=np.floor(x[x.floors%1==0.5].floors)\n",
    "\n",
    "    x['living_per_floors']=x['sqft_living']/x['floors']\n",
    "    x['total_score']=x['condition']+x['grade']+x['view']\n",
    "    x['living_per_lot']=x['sqft_living']/x['sqft_lot']\n",
    "    x['diff_of_rooms']=np.abs(x['bedrooms']-x['bathrooms'])\n",
    "    x['diff_lots']=np.abs(x['sqft_lot15']-x['sqft_lot'])\n",
    "    x['diff_living']=np.abs(x['sqft_living15']-x['sqft_living'])\n",
    "    x['diff_living_per_floor']=(x.sqft_living15-x.sqft_living)/x.floors\n",
    "    x['exist_special']=x.garret+x.waterfront+x.whether_to_renovated\n",
    "\n",
    "    return x\n",
    "\n",
    "data=feature(data)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "200283a8d82a4f8c1951013961b5af3f91cc8be1"
   },
   "source": [
    "### 각 변수들의 분포 확인\n",
    "한쪽으로 치우친 분포는 모델이 결과를 예측하기에 좋지 않은 영향을 미치므로 다듬어줄 필요가 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c2aa785314a8bb8d9f84bbc17cb55e38c564a8f3"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(6, 5, figsize=(20, 20), constrained_layout=True)\n",
    "\n",
    "# id 변수(count==0인 경우)는 제외하고 분포를 확인합니다.\n",
    "count = 1\n",
    "columns = data.columns\n",
    "for row in range(6):\n",
    "    for col in range(5):\n",
    "        sns.kdeplot(data=data[columns[count]], ax=ax[row][col])\n",
    "        ax[row][col].set_title(columns[count], fontsize=15)\n",
    "        count += 1\n",
    "        if count == 29 :\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b377cd53ae25ab16f09d303c5cf0019bc004f465"
   },
   "source": [
    "price, bedrooms, sqft_living, sqft_lot, sqft_above, sqft_basement 변수가 한쪽으로 치우친 경향을 보였습니다.<br>\n",
    "log-scaling을 통해 데이터 분포를 정규분포에 가깝게 만들어 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "24bb873fdfcdf1511b75aff69456b49d36f8f637"
   },
   "outputs": [],
   "source": [
    "skew_columns = ['bedrooms', 'sqft_living', 'sqft_lot', 'sqft_above', 'sqft_basement',\n",
    "                'sqft_lot15', 'sqft_living15','living_per_floors','diff_lots','diff_living']\n",
    "\n",
    "for c in skew_columns:\n",
    "    data[c] = np.log1p(data[c].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "876da0a04810168164a97239fc809ea38b277cdb"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 5, figsize=(20, 10),constrained_layout=True)\n",
    "\n",
    "count = 0\n",
    "for row in range(2):\n",
    "    for col in range(5):\n",
    "        if count == 10:\n",
    "            break\n",
    "        sns.kdeplot(data=data[skew_columns[count]], ax=ax[row][col])\n",
    "        ax[row][col].set_title(skew_columns[count], fontsize=15)\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5923d97d51ae10050473c02eb8d56afa6d3e7567"
   },
   "source": [
    "어느정도 치우침이 줄어든 분포를 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "b4d31773ba934e8b48564fb8207df9e574b3a195",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15035, 29)\n",
      "(6468, 29)\n"
     ]
    }
   ],
   "source": [
    "sub = data.iloc[train_len:, :]\n",
    "x = data.iloc[:train_len, :]\n",
    "\n",
    "print(x.shape)\n",
    "print(sub.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a4afe676edcf34f694c95c3f0e6287d13edaee26"
   },
   "source": [
    "---\n",
    "## 3. 모델링\n",
    "### Average Blending\n",
    "여러가지 모델의 결과를 산술 평균을 통해 Blending 모델을 만들겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "296645421a135dc34c45f822ce73d31eeb107bdc"
   },
   "outputs": [],
   "source": [
    "random_state=2020 \n",
    "\n",
    "rdforest = RandomForestRegressor(random_state=random_state)\n",
    "gboost = GradientBoostingRegressor(random_state=random_state)\n",
    "xgboost = xgb.XGBRegressor(random_state=random_state)\n",
    "lightgbm = lgb.LGBMRegressor(random_state=random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearch\n",
    "GridSearch를 통해 최적의 하이퍼파라미터 값을 찾아냅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_GridSearch(model, train, y, param_grid, verbose=0):\n",
    "    # 1. GridSearchCV 모델로 초기화\n",
    "    grid_model = GridSearchCV(model, param_grid=param_grid, scoring='neg_mean_squared_error', \\\n",
    "                              cv=5, verbose=verbose)\n",
    "    \n",
    "    # 2. 모델 fitting\n",
    "    grid_model.fit(train, y)\n",
    "\n",
    "    # 3. 결과값 저장\n",
    "    params = grid_model.cv_results_['params']\n",
    "    score = grid_model.cv_results_['mean_test_score']\n",
    "    \n",
    "    # 4. 데이터 프레임 생성\n",
    "    results = pd.DataFrame(params)\n",
    "    results['score'] = score\n",
    "    \n",
    "    # 5. RMSLE 값 계산 후 정렬\n",
    "    results['RMSLE'] = np.sqrt(-1 * results['score'])\n",
    "    results = results.sort_values('RMSLE')\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "1. GridSearchCV 모델로 `model`을 초기화합니다.\n",
    "2. 모델을 fitting 합니다.\n",
    "3. params, score에 각 조합에 대한 결과를 저장합니다. \n",
    "4. 데이터 프레임을 생성하고, RMSLE 값을 추가한 후 점수가 높은 순서로 정렬한 `results`를 반환합니다.\n",
    "\n",
    "\n",
    "### RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdforest_grid = {\n",
    "    'max_depth': [10],\n",
    "    'n_estimators': [600],\n",
    "    'min_samples_leaf': [2],\n",
    "    'min_samples_split': [2]\n",
    "}\n",
    "\n",
    "result = my_GridSearch(rdforest, x.values, y, rdforest_grid)\n",
    "result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdforest = RandomForestRegressor(max_depth=10,min_samples_leaf=2,min_samples_split=2,\n",
    "                                 n_estimators=600,random_state=random_state)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### GradientBoosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gboost_grid = {\n",
    "    'max_depth' : [7], \n",
    "    'n_estimators': [500], \n",
    "    'learning_rate':[0.1]\n",
    "}\n",
    "\n",
    "result = my_GridSearch(gboost, x.values, y, gboost_grid)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gboost = GradientBoostingRegressor(learning_rate=0.1,max_depth=7,\n",
    "                                   n_estimators=500, random_state=random_state)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "xgboost_grid = {\n",
    "    'max_depth': [7], \n",
    "    'n_estimators': [500], \n",
    "    'learning_rate':[0.2], \n",
    "    'gamma': [2]\n",
    "}\n",
    "\n",
    "result = my_GridSearch(xgboost, x.values, y, xgboost_grid)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost = xgb.XGBRegressor(gamma=1.0,learning_rate=0.2,max_depth=5,\n",
    "                           n_estimators=32, random_state=random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lightgbm_grid = {\n",
    "    'max_depth': [5],\n",
    "    'n_estimators': [1100],\n",
    "    'learning_rate': [0.09]\n",
    "}\n",
    "\n",
    "result = my_GridSearch(lightgbm, x.values, y, lightgbm_grid)\n",
    "result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lightgbm = lgb.LGBMRegressor(learning_rate=0.09, max_depth=5, \n",
    "                             n_estimators=1100, random_state=random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Average Blending**을 위해 `models`를 정의해줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [{'model':rdforest, 'name': 'RandomForest'}, \n",
    "          {'model':gboost, 'name':'GradientBoosting'}, \n",
    "          {'model':xgboost, 'name':'XGBoost'},\n",
    "          {'model':lightgbm, 'name':'LightGBM'}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "578896883c6b8c6a2c5785a93121b62506b22a21"
   },
   "source": [
    "---\n",
    "## Cross Validation\n",
    "교차 검증을 통해 모델의 성능을 간단히 평가하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4b48689d7989107ea3524126c330e2225a58e4d3"
   },
   "outputs": [],
   "source": [
    "def get_cv_score(models):\n",
    "    kfold = KFold(n_splits=5).get_n_splits(x.values)\n",
    "    for m in models:\n",
    "        CV_score = np.mean(cross_val_score(m['model'], X=x.values, y=y, cv=kfold))\n",
    "        print(f\"Model: {m['name']}, CV score:{CV_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "53ea586dd0b4fe5481db7bfb9cbcb998ef88b648"
   },
   "outputs": [],
   "source": [
    "get_cv_score(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in models:\n",
    "    print(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a26c1d6aa9b779077f84ec60b7f29385fc2e058b"
   },
   "source": [
    "### Make Submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1004d9b01d1c3068d9e8a81f263315435478e591"
   },
   "source": [
    "회귀 모델의 경우에는 cross_val_score 함수가 R<sup>2</sup>를 반환합니다.<br>\n",
    "R<sup>2</sup> 값이 1에 가까울수록 모델이 데이터를 잘 표현함을 나타냅니다. 4개 트리 모델이 상당히 훈련 데이터에 대해 괜찮은 성능을 보여주고 있습니다.<br> 훈련 데이터셋으로 4개 모델을 학습시키고, Average Blending을 통해 제출 결과를 만들겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_uuid": "20af2394b94bdc14fe1b23688874fadbf1c2846a"
   },
   "outputs": [],
   "source": [
    "def AveragingBlending(models, x, y, sub_x):\n",
    "    #모델 학습\n",
    "    for m in models : \n",
    "        m['model'].fit(x.values, y)\n",
    "    \n",
    "    #학습 결과\n",
    "    predictions = np.column_stack([\n",
    "        m['model'].predict(sub_x.values) for m in models\n",
    "    ])\n",
    "    \n",
    "    return np.mean(predictions, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_uuid": "f7bdb1c740291e6d1721cf02cd3f59bb79153c87"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6468\n"
     ]
    }
   ],
   "source": [
    "y_pred = AveragingBlending(models, x, y, sub)\n",
    "print(len(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_uuid": "9c9d0901bcf5e4754b40a6922292c04951b81bae"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15035</td>\n",
       "      <td>5.201423e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15036</td>\n",
       "      <td>4.535527e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15037</td>\n",
       "      <td>1.391494e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15038</td>\n",
       "      <td>3.107995e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15039</td>\n",
       "      <td>3.180907e+05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id         price\n",
       "0  15035  5.201423e+05\n",
       "1  15036  4.535527e+05\n",
       "2  15037  1.391494e+06\n",
       "3  15038  3.107995e+05\n",
       "4  15039  3.180907e+05"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub = pd.DataFrame(data={'id':sub_id,'price':y_pred})\n",
    "sub.to_csv('submission.csv', index=False)\n",
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1 = sub['price'].quantile(0.0042)\n",
    "q2 = sub['price'].quantile(0.99)\n",
    "\n",
    "sub['price'] = sub['price'].apply(lambda x:x if x> q1 else x* 0.77)\n",
    "sub['price'] = sub['price'].apply(lambda x:x if x<q2 else x*1.1)\n",
    "\n",
    "sub.to_csv('submission.csv', index= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 회고\n",
    "캐글 가입부터 submission까지의 전과정을 경험하면서 전체적인 진행방식에 대하여 이해하였습니다. 또한 캐글 참가자분들이 사이트에 올려주신 여러가지 방식들을 통해 아주 다양한 접근법이 있다는 것을 알게 되었습니다. 항상 학습을 하면서 느끼는 것이지만 시간이 너무 오래 걸려 새로운 방식을 공부하여 적용시켜야겠다는 생각이 들었습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 데이터 전처리, 모델학습, 예측의 전체 과정을 거쳐 캐글 submission까지 전과정이 성공적으로 진행되었는가?\n",
    "- 제출된 노트북이 캐글 커널로 사용될 수 있을 만큼 전처리, 학습, 최적화 진행 과정이 체계적으로 기술되었는가?\n",
    "- 다양한 피처 엔지니어링과 하이퍼 파라미터 튜닝 등의 최적화 기법을 통해 캐글 리더보드의 Private score 기준 110000 이하의 점수를 얻었는가?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
