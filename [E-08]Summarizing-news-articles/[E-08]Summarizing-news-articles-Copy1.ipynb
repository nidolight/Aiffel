{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50475fa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /aiffel/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "from bs4 import BeautifulSoup \n",
    "from tensorflow.keras.preprocessing.text import Tokenizer \n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import urllib.request\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module='bs4')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b472c68",
   "metadata": {},
   "source": [
    "## Step 1. 데이터 수집하기\n",
    "이 데이터는 기사의 본문에 해당되는 text와 headlines 두 가지 열로 구성되어져 있습니다.\n",
    "추상적 요약을 하는 경우에는 text를 본문, headlines를 이미 요약된 데이터로 삼아서 모델을 학습해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "edae9c15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headlines</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>43777</th>\n",
       "      <td>In a first, Delhi to procure wind power to mee...</td>\n",
       "      <td>In a first, Delhi's power distribution compani...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92106</th>\n",
       "      <td>TV actor Parth Samthaan booked for molestation</td>\n",
       "      <td>Television actor Parth Samthaan was on Sunday ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31341</th>\n",
       "      <td>American woman earns fourth degree at the age ...</td>\n",
       "      <td>American woman Annie Dillard from South Caroli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49861</th>\n",
       "      <td>Job loss fears in IT industry highly exaggerat...</td>\n",
       "      <td>Talking about automation at a recent event, Ta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93865</th>\n",
       "      <td>In Pictures: The Barjot Mud Run held in Switze...</td>\n",
       "      <td>The annual 'Barjot Run' obstacle race was held...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4329</th>\n",
       "      <td>NASA's 1st woman exec, 'mother of Hubble' pass...</td>\n",
       "      <td>The first-ever woman to hold an executive posi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14581</th>\n",
       "      <td>Tata's Trent may buy Lodha office space for Ã¢...</td>\n",
       "      <td>Tata Group's retail arm Trent is in advanced t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16084</th>\n",
       "      <td>India has 19 judges per 10 lakh people: Law Mi...</td>\n",
       "      <td>India has 19 judges per 10 lakh people on an a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22187</th>\n",
       "      <td>Having family of my own the goal: Priyanka's r...</td>\n",
       "      <td>Priyanka Chopra's rumoured fiancÃÂ© Nick Jona...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12569</th>\n",
       "      <td>World's longest sea-crossing bridge spanning 5...</td>\n",
       "      <td>Chinese President Xi Jinping has officially op...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               headlines  \\\n",
       "43777  In a first, Delhi to procure wind power to mee...   \n",
       "92106     TV actor Parth Samthaan booked for molestation   \n",
       "31341  American woman earns fourth degree at the age ...   \n",
       "49861  Job loss fears in IT industry highly exaggerat...   \n",
       "93865  In Pictures: The Barjot Mud Run held in Switze...   \n",
       "4329   NASA's 1st woman exec, 'mother of Hubble' pass...   \n",
       "14581  Tata's Trent may buy Lodha office space for Ã¢...   \n",
       "16084  India has 19 judges per 10 lakh people: Law Mi...   \n",
       "22187  Having family of my own the goal: Priyanka's r...   \n",
       "12569  World's longest sea-crossing bridge spanning 5...   \n",
       "\n",
       "                                                    text  \n",
       "43777  In a first, Delhi's power distribution compani...  \n",
       "92106  Television actor Parth Samthaan was on Sunday ...  \n",
       "31341  American woman Annie Dillard from South Caroli...  \n",
       "49861  Talking about automation at a recent event, Ta...  \n",
       "93865  The annual 'Barjot Run' obstacle race was held...  \n",
       "4329   The first-ever woman to hold an executive posi...  \n",
       "14581  Tata Group's retail arm Trent is in advanced t...  \n",
       "16084  India has 19 judges per 10 lakh people on an a...  \n",
       "22187  Priyanka Chopra's rumoured fiancÃÂ© Nick Jona...  \n",
       "12569  Chinese President Xi Jinping has officially op...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import urllib.request\n",
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/sunnysai12345/News_Summary/master/news_summary_more.csv\", filename=\"news_summary_more.csv\")\n",
    "data = pd.read_csv('news_summary_more.csv', encoding='iso-8859-1')\n",
    "\n",
    "data.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c4d1d4",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 2. 데이터 전처리하기 (추상적 요약)\n",
    "\n",
    "### 중복 샘플 제거\n",
    "우선 `drop_duplicates()`을 사용하여 중복 샘플을 제거합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "452c20bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "headlines 열에서 중복을 배제한 유일한 샘플의 수 : 98280\n",
      "text 열에서 중복을 배제한 유일한 샘플의 수 : 98360\n"
     ]
    }
   ],
   "source": [
    "print('headlines 열에서 중복을 배제한 유일한 샘플의 수 :', data['headlines'].nunique())\n",
    "print('text 열에서 중복을 배제한 유일한 샘플의 수 :', data['text'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d73ac010",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플수 : 98360\n"
     ]
    }
   ],
   "source": [
    "# inplace=True 를 설정하면 DataFrame 타입 값을 return 하지 않고 data 내부를 직접적으로 바꿉니다\n",
    "data.drop_duplicates(subset = ['text'], inplace=True)\n",
    "print('전체 샘플수 :', (len(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f4f79b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "headlines    0\n",
      "text         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "38d6f5f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플수 : 98360\n"
     ]
    }
   ],
   "source": [
    "data.dropna(axis=0, inplace=True)\n",
    "print('전체 샘플수 :', (len(data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d76afe",
   "metadata": {},
   "source": [
    "### 텍스트 정규화와 불용어 제거\n",
    "아래와 같이 dictionary를 구성하여 학습 전에 미리 같은 표현으로 통일시켜줍니다. 이러한 정규화를 통해 학습을 좀 더 정확하고 효율적이게 할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5304217d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정규화 사전의 수:  120\n"
     ]
    }
   ],
   "source": [
    "contractions = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\",\n",
    "                           \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\",\n",
    "                           \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",\n",
    "                           \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\",\n",
    "                           \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\",\n",
    "                           \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\",\n",
    "                           \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\",\n",
    "                           \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\n",
    "                           \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\",\n",
    "                           \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\",\n",
    "                           \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\",\n",
    "                           \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\",\n",
    "                           \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\",\n",
    "                           \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\",\n",
    "                           \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\",\n",
    "                           \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",\n",
    "                           \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\",\n",
    "                           \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\",\n",
    "                           \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\",\n",
    "                           \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\",\n",
    "                           \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n",
    "                           \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\",\n",
    "                           \"you're\": \"you are\", \"you've\": \"you have\"}\n",
    "\n",
    "print(\"정규화 사전의 수: \", len(contractions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba779e8",
   "metadata": {},
   "source": [
    "\n",
    "- **불용어(stopwords)**: 일반적으로 텍스트에는 자주 등장하지만 자연어 처리를 할 때 실질적으로 별 도움이 되지 않는 단어들\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "494ad3d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "불용어 개수 : 179\n",
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "print('불용어 개수 :', len(stopwords.words('english') ))\n",
    "print(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1982273c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 전처리 함수\n",
    "def preprocess_sentence(sentence, remove_stopwords=True):\n",
    "    sentence = sentence.lower() \n",
    "    sentence = BeautifulSoup(sentence, \"lxml\").text \n",
    "    sentence = re.sub(r'\\([^)]*\\)', '', sentence) \n",
    "    sentence = re.sub('\"','', sentence) \n",
    "    sentence = ' '.join([contractions[t] if t in contractions else t for t in sentence.split(\" \")]) \n",
    "    sentence = re.sub(r\"'s\\b\",\"\", sentence) \n",
    "    sentence = re.sub(\"[^a-zA-Z]\", \" \", sentence) \n",
    "    sentence = re.sub('[m]{2,}', 'mm', sentence)\n",
    "    \n",
    "    # 불용어 제거 (text)\n",
    "    if remove_stopwords:\n",
    "        tokens = ' '.join(word for word in sentence.split() if not word in stopwords.words('english') if len(word) > 1)\n",
    "    # 불용어 미제거 (headlines)\n",
    "    else:\n",
    "        tokens = ' '.join(word for word in sentence.split() if len(word) > 1)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a296f4a1",
   "metadata": {},
   "source": [
    "### 텍스트 전처리\n",
    "\n",
    "텍스트 정규화와 불용어 제거 등을 수행하는 `preprocess_sentence`함수를 만들어줍니다. 아래와 같은 작업을 수행합니다.\n",
    "\n",
    "- 텍스트 소문자화\n",
    "- `<br />`, `<a href = ...>` 등의 html 태그 제거\n",
    "- 괄호로 닫힌 문자열 (...) 제거 Ex) my husband (and myself!) for => my husband for\n",
    "- 쌍따옴표 \" 제거\n",
    "- 만들어둔 약어 dictionary를 통해 약어 **정규화**\n",
    "- 소유격 제거. Ex) roland's -> roland\n",
    "- 영어 외 문자(숫자, 특수문자 등) 공백으로 변환\n",
    "- m이 3개 이상이면 2개로 변경. Ex) ummmmmmm yeah -> umm yeah\n",
    "- **불용어 제거**\n",
    "\n",
    "이때 불용어의 제거 여부는 `remove_stopwords`인자를 통해 결정하게 됩니다.<br>\n",
    "이렇게 하여 본문인 text에서는 불용어를 제거하고 요약인 headlines에서는 불용어를 제거하지 않도록 하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d62598c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text:  everything bought great infact ordered twice third ordered wasfor mother father\n",
      "headlines: great way to start the day\n"
     ]
    }
   ],
   "source": [
    "temp_text = 'Everything I bought was great, infact I ordered twice and the third ordered was<br />for my mother and father.'\n",
    "temp_headlines = 'Great way to start (or finish) the day!!!'\n",
    "\n",
    "print(\"text: \", preprocess_sentence(temp_text))\n",
    "print(\"headlines:\", preprocess_sentence(temp_headlines, False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0560ad3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text 전처리 후 결과:  ['saurav kant alumnus upgrad iiit pg program machine learning artificial intelligence sr systems engineer infosys almost years work experience program upgrad degree career support helped transition data scientist tech mahindra salary hike upgrad online power learning powered lakh careers', 'kunal shah credit card bill payment platform cred gave users chance win free food swiggy one year pranav kaushik delhi techie bagged reward spending cred coins users get one cred coin per rupee bill paid used avail rewards brands like ixigo bookmyshow ubereats cult fit', 'new zealand defeated india wickets fourth odi hamilton thursday win first match five match odi series india lost international match rohit sharma captaincy consecutive victories dating back march match witnessed india getting seventh lowest total odi cricket history', 'aegon life iterm insurance plan customers enjoy tax benefits premiums paid save taxes plan provides life cover age years also customers options insure critical illnesses disability accidental death benefit rider life cover age years', 'speaking sexual harassment allegations rajkumar hirani sonam kapoor said known hirani many years true metoo movement get derailed metoo movement always believe woman case need reserve judgment added hirani accused assistant worked sanju']\n"
     ]
    }
   ],
   "source": [
    "clean_text = []\n",
    "# 전체 Text 데이터에 대한 전처리 : 10분 이상 시간이 걸릴 수 있습니다. \n",
    "for s in data['text']:\n",
    "    clean_text.append(preprocess_sentence(s))\n",
    "\n",
    "# 전처리 후 출력\n",
    "print(\"text 전처리 후 결과: \", clean_text[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4f4601e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "headlines 전처리 후 결과:  ['upgrad learner switches to career in ml al with salary hike', 'delhi techie wins free food from swiggy for one year on cred', 'new zealand end rohit sharma led india match winning streak', 'aegon life iterm insurance plan helps customers save tax', 'have known hirani for yrs what if metoo claims are not true sonam']\n"
     ]
    }
   ],
   "source": [
    "clean_headlines = []\n",
    "# 전체 headlines 데이터에 대한 전처리 : 5분 이상 시간이 걸릴 수 있습니다. \n",
    "for s in data['headlines']:\n",
    "    clean_headlines.append(preprocess_sentence(s, False))\n",
    "\n",
    "print(\"headlines 전처리 후 결과: \", clean_headlines[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa6dc1d",
   "metadata": {},
   "source": [
    "데이터 정제 과정에서 문장의 모든 단어가 사라지는 경우가 있을 수 있으므로 확인해 줍니다.<br>\n",
    "해당 경우의 값들은 사용하지 않으니 제거해줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b31771f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "headlines    0\n",
       "text         0\n",
       "Text         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Text'] = clean_text\n",
    "data['headlines'] = clean_headlines\n",
    "\n",
    "# 빈 값을 Null 값으로 변환\n",
    "data.replace('', np.nan, inplace=True)\n",
    "\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dd967131",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플수 : 98360\n"
     ]
    }
   ],
   "source": [
    "data.dropna(axis=0, inplace=True)\n",
    "print('전체 샘플수 :', (len(data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a70b40a6",
   "metadata": {},
   "source": [
    "### 샘플의 최대 길이 정하기\n",
    "학습에 사용될 데이터의 길이는 일정해야 합니다. 적절한 최대 길이를 다음과 같은 과정을 통해 구해봅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1955c4de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "텍스트의 최소 길이 : 1\n",
      "텍스트의 최대 길이 : 91\n",
      "텍스트의 평균 길이 : 58.23813542090281\n",
      "요약의 최소 길이 : 1\n",
      "요약의 최대 길이 : 16\n",
      "요약의 평균 길이 : 9.299532330215534\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 길이 분포 출력\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "text_len = [len(s.split()) for s in data['text']]\n",
    "headlines_len = [len(s.split()) for s in data['headlines']]\n",
    "\n",
    "print('텍스트의 최소 길이 : {}'.format(np.min(text_len)))\n",
    "print('텍스트의 최대 길이 : {}'.format(np.max(text_len)))\n",
    "print('텍스트의 평균 길이 : {}'.format(np.mean(text_len)))\n",
    "print('요약의 최소 길이 : {}'.format(np.min(headlines_len)))\n",
    "print('요약의 최대 길이 : {}'.format(np.max(headlines_len)))\n",
    "print('요약의 평균 길이 : {}'.format(np.mean(headlines_len)))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.boxplot(text_len)\n",
    "plt.title('Text')\n",
    "plt.subplot(1,2,2)\n",
    "plt.boxplot(headlines_len)\n",
    "plt.title('headlines')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.title('Text')\n",
    "plt.hist(text_len, bins = 40)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show()\n",
    "\n",
    "plt.title('headlines')\n",
    "plt.hist(headlines_len, bins = 40)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "53f8b4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_max_len = 60\n",
    "headlines_max_len = 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cd6a5eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def below_threshold_len(max_len, nested_list):\n",
    "  cnt = 0\n",
    "  for s in nested_list:\n",
    "    if(len(s.split()) <= max_len):\n",
    "        cnt = cnt + 1\n",
    "  print('전체 샘플 중 길이가 %s 이하인 샘플의 비율: %s'%(max_len, (cnt / len(nested_list))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6bcb644d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플 중 길이가 60 이하인 샘플의 비율: 0.997448149654331\n",
      "전체 샘플 중 길이가 13 이하인 샘플의 비율: 0.9981699877999186\n"
     ]
    }
   ],
   "source": [
    "below_threshold_len(text_max_len, data['text'])\n",
    "below_threshold_len(headlines_max_len, data['headlines'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c52b73",
   "metadata": {},
   "source": [
    "임의로 text의 최대길이를 60, headlines의 최대길이를 13로 지정하였을 때 모든 샘플을 포함할 수 있는 것을 확인할 수 있습니다.<br>\n",
    "\n",
    "### 시작 토큰과 종료 토큰 추가하기\n",
    "디코더는 시작 토큰을 입력받아 문장을 생성하기 시작하고, 종료 토큰을 예측한 순간에 문장 생성을 멈추는 과정을 수행합니다.<br>\n",
    "시작 토큰은 `sostoken`, 종료 토큰은 `eostoken`이라 임의로 명하고 샘플 앞, 뒤로 추가해 줍니다.\n",
    "- `decoder_input`: 디코더의 입력에 해당하면서 시작 토큰이 맨 앞에 있는 문장\n",
    "- `decoder_target`: 디코더의 출력 또는 레이블에 해당되면서 종료 토큰이 맨 뒤에 붙는 문장\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5f1d1bed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headlines</th>\n",
       "      <th>text</th>\n",
       "      <th>Text</th>\n",
       "      <th>decoder_input</th>\n",
       "      <th>decoder_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>upgrad learner switches to career in ml al wit...</td>\n",
       "      <td>Saurav Kant, an alumnus of upGrad and IIIT-B's...</td>\n",
       "      <td>saurav kant alumnus upgrad iiit pg program mac...</td>\n",
       "      <td>sostoken upgrad learner switches to career in ...</td>\n",
       "      <td>upgrad learner switches to career in ml al wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>delhi techie wins free food from swiggy for on...</td>\n",
       "      <td>Kunal Shah's credit card bill payment platform...</td>\n",
       "      <td>kunal shah credit card bill payment platform c...</td>\n",
       "      <td>sostoken delhi techie wins free food from swig...</td>\n",
       "      <td>delhi techie wins free food from swiggy for on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>new zealand end rohit sharma led india match w...</td>\n",
       "      <td>New Zealand defeated India by 8 wickets in the...</td>\n",
       "      <td>new zealand defeated india wickets fourth odi ...</td>\n",
       "      <td>sostoken new zealand end rohit sharma led indi...</td>\n",
       "      <td>new zealand end rohit sharma led india match w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aegon life iterm insurance plan helps customer...</td>\n",
       "      <td>With Aegon Life iTerm Insurance plan, customer...</td>\n",
       "      <td>aegon life iterm insurance plan customers enjo...</td>\n",
       "      <td>sostoken aegon life iterm insurance plan helps...</td>\n",
       "      <td>aegon life iterm insurance plan helps customer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>have known hirani for yrs what if metoo claims...</td>\n",
       "      <td>Speaking about the sexual harassment allegatio...</td>\n",
       "      <td>speaking sexual harassment allegations rajkuma...</td>\n",
       "      <td>sostoken have known hirani for yrs what if met...</td>\n",
       "      <td>have known hirani for yrs what if metoo claims...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           headlines  \\\n",
       "0  upgrad learner switches to career in ml al wit...   \n",
       "1  delhi techie wins free food from swiggy for on...   \n",
       "2  new zealand end rohit sharma led india match w...   \n",
       "3  aegon life iterm insurance plan helps customer...   \n",
       "4  have known hirani for yrs what if metoo claims...   \n",
       "\n",
       "                                                text  \\\n",
       "0  Saurav Kant, an alumnus of upGrad and IIIT-B's...   \n",
       "1  Kunal Shah's credit card bill payment platform...   \n",
       "2  New Zealand defeated India by 8 wickets in the...   \n",
       "3  With Aegon Life iTerm Insurance plan, customer...   \n",
       "4  Speaking about the sexual harassment allegatio...   \n",
       "\n",
       "                                                Text  \\\n",
       "0  saurav kant alumnus upgrad iiit pg program mac...   \n",
       "1  kunal shah credit card bill payment platform c...   \n",
       "2  new zealand defeated india wickets fourth odi ...   \n",
       "3  aegon life iterm insurance plan customers enjo...   \n",
       "4  speaking sexual harassment allegations rajkuma...   \n",
       "\n",
       "                                       decoder_input  \\\n",
       "0  sostoken upgrad learner switches to career in ...   \n",
       "1  sostoken delhi techie wins free food from swig...   \n",
       "2  sostoken new zealand end rohit sharma led indi...   \n",
       "3  sostoken aegon life iterm insurance plan helps...   \n",
       "4  sostoken have known hirani for yrs what if met...   \n",
       "\n",
       "                                      decoder_target  \n",
       "0  upgrad learner switches to career in ml al wit...  \n",
       "1  delhi techie wins free food from swiggy for on...  \n",
       "2  new zealand end rohit sharma led india match w...  \n",
       "3  aegon life iterm insurance plan helps customer...  \n",
       "4  have known hirani for yrs what if metoo claims...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 요약 데이터에는 시작 토큰과 종료 토큰을 추가한다.\n",
    "data['decoder_input'] = data['headlines'].apply(lambda x : 'sostoken '+ x)\n",
    "data['decoder_target'] = data['headlines'].apply(lambda x : x + ' eostoken')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "af717aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#인코더의 입력, 디코더의 입력과 레이블을 각각 다시 Numpy 타입으로 저장합니다.\n",
    "encoder_input = np.array(data['text']) \n",
    "decoder_input = np.array(data['decoder_input'])\n",
    "decoder_target = np.array(data['decoder_target'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f341f1",
   "metadata": {},
   "source": [
    "### 훈련 데이터와 테스트 데이터 분리\n",
    "\n",
    "indices라는 랜덤 정수 시퀀스를 만들어 데이터를 무작위 순서로 섞습니다.<br>\n",
    "이후 섞인 데이터를 8:2의 비율로 훈련 데이터와 테스트 데이터로 분리해 줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "edf43eab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트 데이터의 수 : 19672\n"
     ]
    }
   ],
   "source": [
    "indices = np.arange(encoder_input.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "encoder_input = encoder_input[indices]\n",
    "decoder_input = decoder_input[indices]\n",
    "decoder_target = decoder_target[indices]\n",
    "\n",
    "n_of_val = int(len(encoder_input)*0.2) # 8:2 분리\n",
    "print('테스트 데이터의 수 :', n_of_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c1ce17cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 데이터의 개수 : 78688\n",
      "훈련 레이블의 개수 : 78688\n",
      "테스트 데이터의 개수 : 19672\n",
      "테스트 레이블의 개수 : 19672\n"
     ]
    }
   ],
   "source": [
    "encoder_input_train = encoder_input[:-n_of_val]\n",
    "decoder_input_train = decoder_input[:-n_of_val]\n",
    "decoder_target_train = decoder_target[:-n_of_val]\n",
    "\n",
    "encoder_input_test = encoder_input[-n_of_val:]\n",
    "decoder_input_test = decoder_input[-n_of_val:]\n",
    "decoder_target_test = decoder_target[-n_of_val:]\n",
    "\n",
    "print('훈련 데이터의 개수 :', len(encoder_input_train))\n",
    "print('훈련 레이블의 개수 :', len(decoder_input_train))\n",
    "print('테스트 데이터의 개수 :', len(encoder_input_test))\n",
    "print('테스트 레이블의 개수 :', len(decoder_input_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd6575b",
   "metadata": {},
   "source": [
    "### 정수 인코딩\n",
    "텍스트를 모델에 학습시키기 위해서는 정수로 만들어야 합니다.\n",
    "Keras의 토크나이저를 사용하여 텍스트를 정수로 쉽게 변환할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "307363c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_tokenizer = Tokenizer()\n",
    "src_tokenizer.fit_on_texts(encoder_input_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7808ab0",
   "metadata": {},
   "source": [
    "위와 같이 입력된 `encoder_input_train`데이터로부터 단어 집합을 생성합니다.<br>\n",
    "생성된 단어들은 토크나이저에 저장되는데 빈도수가 낮은 데이터들은 제외를 하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ffed95ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합(vocabulary)의 크기 : 91170\n",
      "등장 빈도가 6번 이하인 희귀 단어의 수: 66444\n",
      "단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 24726\n",
      "단어 집합에서 희귀 단어의 비율: 72.87923659098388\n",
      "전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 2.728096347562878\n"
     ]
    }
   ],
   "source": [
    "threshold = 7 #임의의 값\n",
    "total_cnt = len(src_tokenizer.word_index) # 단어의 수\n",
    "rare_cnt = 0 # 등장 빈도수가 threshold보다 작은 단어의 개수를 카운트\n",
    "total_freq = 0 # 훈련 데이터의 전체 단어 빈도수 총 합\n",
    "rare_freq = 0 # 등장 빈도수가 threshold보다 작은 단어의 등장 빈도수의 총 합\n",
    "\n",
    "# 단어와 빈도수의 쌍(pair)을 key와 value로 받는다.\n",
    "for key, value in src_tokenizer.word_counts.items():\n",
    "    total_freq = total_freq + value\n",
    "\n",
    "    # 단어의 등장 빈도수가 threshold보다 작으면\n",
    "    if(value < threshold):\n",
    "        rare_cnt = rare_cnt + 1\n",
    "        rare_freq = rare_freq + value\n",
    "\n",
    "print('단어 집합(vocabulary)의 크기 :', total_cnt)\n",
    "print('등장 빈도가 %s번 이하인 희귀 단어의 수: %s'%(threshold - 1, rare_cnt))\n",
    "print('단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 %s'%(total_cnt - rare_cnt))\n",
    "print(\"단어 집합에서 희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)\n",
    "print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "976d7219",
   "metadata": {},
   "source": [
    "등장 빈도가 threshold 값인 7회 미만, 즉 6회 이하인 단어들은 단어 집합에서 72% 이상을 차지합니다.<br>\n",
    "하지만 실제로 훈련 데이터에서 등장 빈도로 차지하는 비중은 상대적으로 적은 수치인 약 2.7%밖에 되지 않습니다.<br>\n",
    "따라서 등장 빈도가 6회 이하인 단어들은 정수 인코딩 과정에서 빼고, 훈련 데이터에서 제거하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "714ab5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_vocab = 24000\n",
    "src_tokenizer = Tokenizer(num_words=src_vocab) # 단어 집합의 크기를 24,000으로 제한\n",
    "src_tokenizer.fit_on_texts(encoder_input_train) # 단어 집합 재생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "69e59b3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3, 463, 32, 55, 673, 8, 3246, 7707, 9187, 14, 373, 4, 9044, 2, 239, 463, 762, 4859, 28, 26, 1246, 45, 635, 893, 77, 44, 2744, 2, 391, 45, 5825, 46, 421, 463, 3446, 23, 25, 265, 7, 1295, 101, 16194, 6731, 27, 92, 2644, 1, 320, 5, 148, 3446, 7, 2305, 101, 14, 10, 473, 1, 1289, 756, 61, 5311], [841, 474, 57, 7321, 5740, 8, 10, 17, 143, 1095, 6321, 37, 3433, 2, 2071, 1, 3433, 5, 1, 41, 6, 29, 11, 130, 23, 38, 598, 19, 1350, 11349, 5740, 27, 92, 10, 11, 130, 8, 398, 21519, 221, 2, 41, 1386, 6, 3460, 643, 21, 10426, 2, 4, 1, 993, 18, 1, 41, 102, 21, 5, 16195, 1179], [150, 11102, 2111, 8, 10, 11, 42, 721, 647, 2, 200, 436, 235, 6, 396, 1646, 2138, 77, 181, 68, 42, 2484, 251, 42, 2683, 414, 420, 31, 3838, 6, 21, 12, 3, 732, 2306, 112, 1842, 3099, 20, 843, 2, 3032, 1, 438, 97, 414, 161, 398, 25, 1, 248, 1842, 5, 631, 1121, 11102, 29]]\n"
     ]
    }
   ],
   "source": [
    "# 텍스트 시퀀스를 정수 시퀀스로 변환\n",
    "encoder_input_train = src_tokenizer.texts_to_sequences(encoder_input_train) \n",
    "encoder_input_test = src_tokenizer.texts_to_sequences(encoder_input_test)\n",
    "\n",
    "# 잘 진행되었는지 샘플 출력\n",
    "print(encoder_input_train[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d97414",
   "metadata": {},
   "source": [
    "headlines 데이터에 대해서도 동일한 작업을 수행해줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bb46c483",
   "metadata": {},
   "outputs": [],
   "source": [
    "tar_tokenizer = Tokenizer()\n",
    "tar_tokenizer.fit_on_texts(decoder_input_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "26c616e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합(vocabulary)의 크기 : 30157\n",
      "등장 빈도가 5번 이하인 희귀 단어의 수: 19737\n",
      "단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 10420\n",
      "단어 집합에서 희귀 단어의 비율: 65.44749146135226\n",
      "전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 4.647297067164234\n"
     ]
    }
   ],
   "source": [
    "threshold = 6 #임의의 값\n",
    "total_cnt = len(tar_tokenizer.word_index) # 단어의 수\n",
    "rare_cnt = 0 # 등장 빈도수가 threshold보다 작은 단어의 개수를 카운트\n",
    "total_freq = 0 # 훈련 데이터의 전체 단어 빈도수 총 합\n",
    "rare_freq = 0 # 등장 빈도수가 threshold보다 작은 단어의 등장 빈도수의 총 합\n",
    "\n",
    "# 단어와 빈도수의 쌍(pair)을 key와 value로 받는다.\n",
    "for key, value in tar_tokenizer.word_counts.items():\n",
    "    total_freq = total_freq + value\n",
    "\n",
    "    # 단어의 등장 빈도수가 threshold보다 작으면\n",
    "    if(value < threshold):\n",
    "        rare_cnt = rare_cnt + 1\n",
    "        rare_freq = rare_freq + value\n",
    "\n",
    "print('단어 집합(vocabulary)의 크기 :', total_cnt)\n",
    "print('등장 빈도가 %s번 이하인 희귀 단어의 수: %s'%(threshold - 1, rare_cnt))\n",
    "print('단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 %s'%(total_cnt - rare_cnt))\n",
    "print(\"단어 집합에서 희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)\n",
    "print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a82f66ca",
   "metadata": {},
   "source": [
    "등장 빈도가 5회 이하인 단어들은 단어 집합에서 72% 이상을 차지합니다.<br>\n",
    "하지만 실제로 훈련 데이터에서 등장 빈도로 차지하는 비중은 상대적으로 적은 수치인 약 6%밖에 되지 않습니다.<br>\n",
    "따라서 등장 빈도가 5회 이하인 단어들은 정수 인코딩 과정에서 빼고, 훈련 데이터에서 제거하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "99e391ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input\n",
      "input  [[1, 64, 26, 657, 5407, 3, 228, 2734, 7, 51], [1, 24, 10, 5205, 313, 6839, 5, 2450, 13, 104], [1, 1336, 199, 2072, 50, 3603, 47, 30, 267, 1475, 6840], [1, 3334, 4280, 18, 9522, 1112, 9], [1, 3413, 3909, 2203, 335, 9, 8200, 1123, 5, 34, 55]]\n",
      "target\n",
      "decoder  [[64, 26, 657, 5407, 3, 228, 2734, 7, 51, 2], [24, 10, 5205, 313, 6839, 5, 2450, 13, 104, 2], [1336, 199, 2072, 50, 3603, 47, 30, 267, 1475, 6840, 2], [3334, 4280, 18, 9522, 1112, 9, 2], [3413, 3909, 2203, 335, 9, 8200, 1123, 5, 34, 55, 2]]\n"
     ]
    }
   ],
   "source": [
    "tar_vocab = 11000\n",
    "tar_tokenizer = Tokenizer(num_words=tar_vocab) \n",
    "tar_tokenizer.fit_on_texts(decoder_input_train)\n",
    "tar_tokenizer.fit_on_texts(decoder_target_train)\n",
    "\n",
    "# 텍스트 시퀀스를 정수 시퀀스로 변환\n",
    "decoder_input_train = tar_tokenizer.texts_to_sequences(decoder_input_train) \n",
    "decoder_target_train = tar_tokenizer.texts_to_sequences(decoder_target_train)\n",
    "decoder_input_test = tar_tokenizer.texts_to_sequences(decoder_input_test)\n",
    "decoder_target_test = tar_tokenizer.texts_to_sequences(decoder_target_test)\n",
    "\n",
    "# 잘 변환되었는지 확인\n",
    "print('input')\n",
    "print('input ',decoder_input_train[:5])\n",
    "print('target')\n",
    "print('decoder ',decoder_target_train[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc4d88d",
   "metadata": {},
   "source": [
    "### 패딩 처리\n",
    "서로 다른 길이의 샘플들을 병렬 처리하기 위해 같은 길이로 맞춰주는 패딩 작업을 해줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "98c0c7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input_train = pad_sequences(encoder_input_train, maxlen=text_max_len, padding='post')\n",
    "encoder_input_test = pad_sequences(encoder_input_test, maxlen=text_max_len, padding='post')\n",
    "decoder_input_train = pad_sequences(decoder_input_train, maxlen=headlines_max_len, padding='post')\n",
    "decoder_target_train = pad_sequences(decoder_target_train, maxlen=headlines_max_len, padding='post')\n",
    "decoder_input_test = pad_sequences(decoder_input_test, maxlen=headlines_max_len, padding='post')\n",
    "decoder_target_test = pad_sequences(decoder_target_test, maxlen=headlines_max_len, padding='post')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa879dc",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 3. 어텐션 메커니즘 사용하기\n",
    "\n",
    "일반적인 seq2seq보다는 어텐션 메커니즘을 사용한 seq2seq를 사용하는 것이 더 나은 성능을 얻을 수 있어요. 실습 내용을 참고하여 어텐션 메커니즘을 사용한 seq2seq를 설계해 보세요.\n",
    "\n",
    "어텐션 메커니즘을 사용하기 위한 모델을 구성합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "18924949",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate, TimeDistributed\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "\n",
    "# 인코더 설계 시작\n",
    "embedding_dim = 128\n",
    "hidden_size = 256\n",
    "\n",
    "# 인코더\n",
    "encoder_inputs = Input(shape=(text_max_len,))\n",
    "\n",
    "# 인코더의 임베딩 층\n",
    "enc_emb = Embedding(src_vocab, embedding_dim)(encoder_inputs)\n",
    "\n",
    "# 인코더의 LSTM 1\n",
    "encoder_lstm1 = LSTM(hidden_size, return_sequences=True, return_state=True ,dropout = 0.4, recurrent_dropout = 0.4)\n",
    "encoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb)\n",
    "\n",
    "# 인코더의 LSTM 2\n",
    "encoder_lstm2 = LSTM(hidden_size, return_sequences=True, return_state=True, dropout=0.4, recurrent_dropout=0.4)\n",
    "encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1)\n",
    "\n",
    "# 인코더의 LSTM 3\n",
    "encoder_lstm3 = LSTM(hidden_size, return_state=True, return_sequences=True, dropout=0.4, recurrent_dropout=0.4)\n",
    "encoder_outputs, state_h, state_c= encoder_lstm3(encoder_output2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3302b092",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    }
   ],
   "source": [
    "# 디코더 설계\n",
    "decoder_inputs = Input(shape=(None,))\n",
    "\n",
    "# 디코더의 임베딩 층\n",
    "dec_emb_layer = Embedding(tar_vocab, embedding_dim)\n",
    "dec_emb = dec_emb_layer(decoder_inputs)\n",
    "\n",
    "# 디코더의 LSTM\n",
    "decoder_lstm = LSTM(hidden_size, return_sequences=True, return_state=True, dropout=0.4, recurrent_dropout=0.2)\n",
    "decoder_outputs, _, _ = decoder_lstm(dec_emb, initial_state=[state_h, state_c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5d624c39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 60)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 60, 128)      3072000     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, 60, 256), (N 394240      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, 60, 256), (N 525312      lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 128)    1408000     input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, 60, 256), (N 525312      lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   [(None, None, 256),  394240      embedding_1[0][0]                \n",
      "                                                                 lstm_2[0][1]                     \n",
      "                                                                 lstm_2[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, None, 11000)  2827000     lstm_3[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 9,146,104\n",
      "Trainable params: 9,146,104\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 디코더의 출력층\n",
    "decoder_softmax_layer = Dense(tar_vocab, activation='softmax')\n",
    "decoder_softmax_outputs = decoder_softmax_layer(decoder_outputs) \n",
    "\n",
    "# 모델 정의\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_softmax_outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e520653",
   "metadata": {},
   "source": [
    "### 어텐션 메커니즘\n",
    "어텐션 메커니즘을 사용하기 위하여 어텐션 신경망 모델을 새로 만들어 줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6457a8c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 60)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 60, 128)      3072000     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, 60, 256), (N 394240      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, 60, 256), (N 525312      lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 128)    1408000     input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, 60, 256), (N 525312      lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   [(None, None, 256),  394240      embedding_1[0][0]                \n",
      "                                                                 lstm_2[0][1]                     \n",
      "                                                                 lstm_2[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "attention_layer (AdditiveAttent (None, None, 256)    256         lstm_3[0][0]                     \n",
      "                                                                 lstm_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concat_layer (Concatenate)      (None, None, 512)    0           lstm_3[0][0]                     \n",
      "                                                                 attention_layer[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, None, 11000)  5643000     concat_layer[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 11,962,360\n",
      "Trainable params: 11,962,360\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import AdditiveAttention\n",
    "\n",
    "# 어텐션 층(어텐션 함수)\n",
    "attn_layer = AdditiveAttention(name='attention_layer')\n",
    "\n",
    "# 인코더와 디코더의 모든 time step의 hidden state를 어텐션 층에 전달하고 결과를 리턴\n",
    "attn_out = attn_layer([decoder_outputs, encoder_outputs])\n",
    "\n",
    "\n",
    "# 어텐션의 결과와 디코더의 hidden state들을 연결\n",
    "decoder_concat_input = Concatenate(axis=-1, name='concat_layer')([decoder_outputs, attn_out])\n",
    "\n",
    "# 디코더의 출력층\n",
    "decoder_softmax_layer = Dense(tar_vocab, activation='softmax')\n",
    "decoder_softmax_outputs = decoder_softmax_layer(decoder_concat_input)\n",
    "\n",
    "# 모델 정의\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_softmax_outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8803ac4d",
   "metadata": {},
   "source": [
    "## 모델 학습\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b1b874",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "308/308 [==============================] - 254s 798ms/step - loss: 5.3339 - val_loss: 4.9601\n",
      "Epoch 2/50\n",
      "308/308 [==============================] - 245s 794ms/step - loss: 4.8182 - val_loss: 4.5925\n",
      "Epoch 3/50\n",
      "308/308 [==============================] - 245s 794ms/step - loss: 4.4881 - val_loss: 4.3284\n",
      "Epoch 4/50\n",
      "308/308 [==============================] - 244s 792ms/step - loss: 4.2444 - val_loss: 4.1655\n",
      "Epoch 5/50\n",
      "308/308 [==============================] - 245s 794ms/step - loss: 4.0518 - val_loss: 4.0209\n",
      "Epoch 6/50\n",
      "308/308 [==============================] - 245s 795ms/step - loss: 3.8890 - val_loss: 3.9196\n",
      "Epoch 7/50\n",
      "308/308 [==============================] - 244s 792ms/step - loss: 3.7494 - val_loss: 3.8188\n",
      "Epoch 8/50\n",
      "308/308 [==============================] - 244s 791ms/step - loss: 3.6292 - val_loss: 3.7577\n",
      "Epoch 9/50\n",
      "308/308 [==============================] - 243s 790ms/step - loss: 3.5194 - val_loss: 3.6847\n",
      "Epoch 10/50\n",
      "308/308 [==============================] - 243s 789ms/step - loss: 3.4255 - val_loss: 3.6378\n",
      "Epoch 11/50\n",
      " 39/308 [==>...........................] - ETA: 3:28 - loss: 3.2986"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')\n",
    "es = EarlyStopping(monitor='val_loss', patience=2, verbose=1) #EarlyStopping은 특정 조건이 충족되면 훈련을 멈춰줍니다.\n",
    "history = model.fit(x=[encoder_input_train, decoder_input_train], y=decoder_target_train, \\\n",
    "          validation_data=([encoder_input_test, decoder_input_test], decoder_target_test), \\\n",
    "          batch_size=256, callbacks=[es], epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b771c51b",
   "metadata": {},
   "source": [
    "### 학습 결과 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf1cf12",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a23c053",
   "metadata": {},
   "source": [
    "## 인퍼런스 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357ff5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_index_to_word = src_tokenizer.index_word # 원문 단어 집합에서 정수 -> 단어를 얻음\n",
    "tar_word_to_index = tar_tokenizer.word_index # 요약 단어 집합에서 단어 -> 정수를 얻음\n",
    "tar_index_to_word = tar_tokenizer.index_word # 요약 단어 집합에서 정수 -> 단어를 얻음\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e759bc33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인코더 설계\n",
    "encoder_model = Model(inputs=encoder_inputs, outputs=[encoder_outputs, state_h, state_c])\n",
    "\n",
    "# 이전 시점의 상태들을 저장하는 텐서\n",
    "decoder_state_input_h = Input(shape=(hidden_size,))\n",
    "decoder_state_input_c = Input(shape=(hidden_size,))\n",
    "\n",
    "dec_emb2 = dec_emb_layer(decoder_inputs)\n",
    "\n",
    "# 문장의 다음 단어를 예측하기 위해서 초기 상태(initial_state)를 이전 시점의 상태로 사용. 이는 뒤의 함수 decode_sequence()에 구현\n",
    "# 훈련 과정에서와 달리 LSTM의 리턴하는 은닉 상태와 셀 상태인 state_h와 state_c를 버리지 않음.\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=[decoder_state_input_h, decoder_state_input_c])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a5a979",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 어텐션 함수\n",
    "decoder_hidden_state_input = Input(shape=(text_max_len, hidden_size))\n",
    "attn_out_inf = attn_layer([decoder_outputs2, decoder_hidden_state_input])\n",
    "decoder_inf_concat = Concatenate(axis=-1, name='concat')([decoder_outputs2, attn_out_inf])\n",
    "\n",
    "# 디코더의 출력층\n",
    "decoder_outputs2 = decoder_softmax_layer(decoder_inf_concat) \n",
    "\n",
    "# 최종 디코더 모델\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + [decoder_hidden_state_input,decoder_state_input_h, decoder_state_input_c],\n",
    "    [decoder_outputs2] + [state_h2, state_c2])\n",
    "\n",
    "print('=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85fa2831",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # 입력으로부터 인코더의 상태를 얻음\n",
    "    e_out, e_h, e_c = encoder_model.predict(input_seq)\n",
    "\n",
    "     # <SOS>에 해당하는 토큰 생성\n",
    "    target_seq = np.zeros((1,1))\n",
    "    target_seq[0, 0] = tar_word_to_index['sostoken']\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition: # stop_condition이 True가 될 때까지 루프 반복\n",
    "\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_token = tar_index_to_word[sampled_token_index]\n",
    "\n",
    "        if (sampled_token!='eostoken'):\n",
    "            decoded_sentence += ' '+sampled_token\n",
    "\n",
    "        #  <eos>에 도달하거나 최대 길이를 넘으면 중단.\n",
    "        if (sampled_token == 'eostoken'  or len(decoded_sentence.split()) >= (headlines_max_len-1)):\n",
    "            stop_condition = True\n",
    "\n",
    "        # 길이가 1인 타겟 시퀀스를 업데이트\n",
    "        target_seq = np.zeros((1,1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        # 상태를 업데이트 합니다.\n",
    "        e_h, e_c = h, c\n",
    "\n",
    "    return decoded_sentence\n",
    "print('=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a52b1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b5252b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원문의 정수 시퀀스를 텍스트 시퀀스로 변환\n",
    "def seq2text(input_seq):\n",
    "    temp=''\n",
    "    for i in input_seq:\n",
    "        if (i!=0):\n",
    "            temp = temp + src_index_to_word[i]+' '\n",
    "    return temp\n",
    "\n",
    "# 요약문의 정수 시퀀스를 텍스트 시퀀스로 변환\n",
    "def seq2headlines(input_seq):\n",
    "    temp=''\n",
    "    for i in input_seq:\n",
    "        if ((i!=0 and i!=tar_word_to_index['sostoken']) and i!=tar_word_to_index['eostoken']):\n",
    "            temp = temp + tar_index_to_word[i] + ' '\n",
    "    return temp\n",
    "\n",
    "print('=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb57c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(50, 100):\n",
    "    print(\"원문 :\", seq2text(encoder_input_test[i]))\n",
    "    print(\"실제 요약 :\", seq2headlines(decoder_input_test[i]))\n",
    "    print(\"예측 요약 :\", decode_sequence(encoder_input_test[i].reshape(1, text_max_len)))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44a8d4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a73513",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67e9429",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c6611fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "048df5e2",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Step 4. 실제 결과와 요약문 비교하기 (추상적 요약)\n",
    "\n",
    "원래의 요약문(headlines 열)과 학습을 통해 얻은 추상적 요약의 결과를 비교해 보세요.\n",
    "\n",
    "Step 5. Summa을 이용해서 추출적 요약해보기\n",
    "\n",
    "추상적 요약은 추출적 요약과는 달리 문장의 표현력을 다양하게 가져갈 수 있지만, 추출적 요약에 비해서 난이도가 높아요. 반대로 말하면 추출적 요약은 추상적 요약에 비해 난이도가 낮고 기존 문장에서 문장을 꺼내오는 것이므로 잘못된 요약이 나올 가능성이 낮아요.\n",
    "\n",
    "Summa의 summarize를 사용하여 추출적 요약을 해보세요"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d4ae9e",
   "metadata": {},
   "source": [
    "1. Abstractive 모델 구성을 위한 텍스트 전처리 단계가 체계적으로 진행되었다.\n",
    "\n",
    "분석단계, 정제단계, 정규화와 불용어 제거, 데이터셋 분리, 인코딩 과정이 빠짐없이 체계적으로 진행되었다.\n",
    "\n",
    "2. 텍스트 요약모델이 성공적으로 학습되었음을 확인하였다.\n",
    "\n",
    "모델학습이 안정적으로 수렴되었음을 그래프를 통해 확인하였으며, 실제 요약문과 유사한 요약문장을 얻을 수 있었다.\n",
    "\n",
    "3. Extractive 요약을 시도해 보고 Abstractive 요약 결과과 함께 비교해 보았다.\n",
    "\n",
    "두 요약 결과를 문법완성도 측면과 핵심단어 포함 측면으로 나누어 비교분석 결과를 제시하였다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82491b12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
